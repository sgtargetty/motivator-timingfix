import 'dart:convert';
import 'dart:typed_data';
import 'dart:io';
import 'package:http/http.dart' as http;

class MotivatorApi {
  final String baseUrl = 'https://motivator-ai-backend.onrender.com';
  
  Future<String> generateLine(
    String task, {
    String? toneStyle,
    String? voiceStyle,
    String? taskType,
  }) async {
    try {
      // ğŸ¯ FIXED: Send full voice format to backend (don't extract)
      final fullVoiceStyle = voiceStyle ?? 'male:Default Male';
      
      print('ğŸš€ Calling generateLine...');
      print('ğŸ“ Task: $task');
      print('ğŸ­ Tone Style: $toneStyle');
      print('ğŸ¤ Original Voice Style: $voiceStyle');
      print('ğŸ¯ Full Voice Style: $fullVoiceStyle');
      print('ğŸ“‹ Task Type: $taskType');
      print('ğŸ”— Endpoint: $baseUrl/generate-line');

      // Build the request body with FULL voice format
      final requestBody = {
        'task': task,
        if (toneStyle != null) 'toneStyle': toneStyle,
        if (fullVoiceStyle.isNotEmpty) 'voiceStyle': fullVoiceStyle,
        if (taskType != null) 'taskType': taskType,
      };

      final response = await http.post(
        Uri.parse('$baseUrl/generate-line'),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode(requestBody),
      );

      print('ğŸŒ Status: ${response.statusCode}');
      print('ğŸ“¦ Response Body: ${response.body}');

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body);
        return data['line'];
      } else {
        throw Exception('âŒ Failed to generate line â€” HTTP ${response.statusCode}');
      }
    } catch (e, stackTrace) {
      print('âŒ Full Exception: $e');
      print('ğŸªµ Stack Trace:\n$stackTrace');
      rethrow;
    }
  }

  Future<Uint8List> generateVoice(
    String text, {
    String? voiceStyle,
    String? toneStyle,
  }) async {
    try {
      // ğŸ¯ FIXED: Send full voice format to backend (don't extract)
      final fullVoiceStyle = voiceStyle ?? 'male:Default Male';
      
      print('ğŸ¤ Calling generateVoice...');
      print('ğŸ“ Text: $text');
      print('ğŸµ Original Voice Style: $voiceStyle');
      print('ğŸ¯ Full Voice Style: $fullVoiceStyle');
      print('ğŸ­ Tone Style: $toneStyle');

      // Build the request body with FULL voice format
      final requestBody = {
        'text': text,
        if (fullVoiceStyle.isNotEmpty) 'voiceStyle': fullVoiceStyle,
        if (toneStyle != null) 'toneStyle': toneStyle,
      };

      print('ğŸ“¤ Sending to backend: ${jsonEncode(requestBody)}');

      final response = await http.post(
        Uri.parse('$baseUrl/generate-voice'),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode(requestBody),
      );

      print('ğŸŒ Voice Status: ${response.statusCode}');

      if (response.statusCode == 200) {
        print('âœ… Voice generated successfully for: $fullVoiceStyle');
        return response.bodyBytes;
      } else {
        print('âŒ Voice generation failed: ${response.body}');
        throw Exception('âŒ Failed to generate voice â€” HTTP ${response.statusCode}');
      }
    } catch (e, stackTrace) {
      print('âŒ Error generating voice: $e');
      print('ğŸªµ Stack trace:\n$stackTrace');
      rethrow;
    }
  }

  // ğŸš€ NEW: Process speech with OpenAI Whisper + GPT extraction
  Future<Map<String, dynamic>> processSpeech(
    String audioFilePath, {
    int? durationSeconds,
  }) async {
    try {
      print('ğŸ¤ Processing speech file: $audioFilePath');
      print('â±ï¸ Duration: ${durationSeconds ?? 0} seconds');

      // Create multipart request
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('$baseUrl/process-speech'),
      );

      // Add audio file
      var audioFile = await http.MultipartFile.fromPath(
        'audio',
        audioFilePath,
        filename: 'recording.m4a', // âœ… M4A
      );
      request.files.add(audioFile);

      // Add duration if provided
      if (durationSeconds != null) {
        request.fields['duration'] = durationSeconds.toString();
      }

      print('ğŸ“¤ Sending audio file to backend...');

      // Send request
      var streamedResponse = await request.send();
      var response = await http.Response.fromStream(streamedResponse);

      print('ğŸŒ Response Status: ${response.statusCode}');
      print('ğŸ“¦ Response Body: ${response.body}');

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body);
        
        // Validate response structure
        if (data['success'] == true && 
            data['transcribedText'] != null && 
            data['extractedData'] != null) {
          
          print('âœ… Speech processed successfully!');
          print('ğŸ“ Transcribed: ${data['transcribedText']}');
          print('ğŸ¤– Extracted: ${data['extractedData']}');
          
          return {
            'transcribedText': data['transcribedText'],
            'extractedData': data['extractedData'],
            'processing': data['processing'] ?? {},
          };
        } else {
          throw Exception('âŒ Invalid response format from backend');
        }
      } else {
        throw Exception('âŒ Speech processing failed â€” HTTP ${response.statusCode}: ${response.body}');
      }
    } catch (e, stackTrace) {
      print('âŒ Error in processSpeech: $e');
      print('ğŸªµ Stack trace:\n$stackTrace');
      rethrow;
    }
  }
}