// lib/screens/widgets/realtime_voice_chat.dart - Complete Voice System with Backchannel

import 'dart:convert';
import 'dart:typed_data';
import 'dart:math' as math;
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:audioplayers/audioplayers.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:http/http.dart' as http;
import 'package:shared_preferences/shared_preferences.dart';
import 'package:uuid/uuid.dart';
import 'dart:async';

// üß† ENHANCED ML SELECTION WITH VARIETY TRACKING
class BackchannelSelector {
  static List<String> _recentlyUsed = [];
  static int _maxHistorySize = 5;

  // üéØ ADVANCED CONTEXT-AWARE SELECTION
  static String selectBackchannelClip(String userMessage, int conversationTurn, Map<String, List<String>> clips) {
    final message = userMessage.toLowerCase();
    
    print("üß† Enhanced ML selecting clip for: '$userMessage' (turn $conversationTurn)");
    
    // üî• MULTI-FACTOR CONTEXT ANALYSIS
    
    // First few turns - establish rapport
    if (conversationTurn <= 2) {
      return _getVariedClip(clips['acknowledgment']!, 'acknowledgment');
    }
    
    // üò¢ EMOTIONAL DISTRESS DETECTION
    if (_containsAny(message, ['problem', 'issue', 'stuck', 'wrong', 'bad', 'terrible', 'awful', 'hate', 'frustrated', 'angry', 'sad', 'depressed'])) {
      return _getVariedClip(clips['empathy']!, 'empathy');
    }
    
    // üéâ EXCITEMENT & SUCCESS DETECTION
    if (_containsAny(message, ['awesome', 'amazing', 'great', 'love', 'fantastic', 'incredible', 'perfect', 'yes!', 'finally', 'success', 'won', 'achieved'])) {
      return _getVariedClip(clips['excitement']!, 'excitement');
    }
    
    // ‚ùì QUESTIONS & CURIOSITY
    if (message.contains('?') || _containsAny(message, ['what', 'how', 'why', 'when', 'where', 'tell me', 'explain', 'help me understand'])) {
      return _getVariedClip(clips['curiosity']!, 'curiosity');
    }
    
    // ‚úÖ AGREEMENT & CONFIRMATION
    if (_containsAny(message, ['exactly', 'yes', 'right', 'agree', 'correct', 'true', 'definitely', 'absolutely', 'you bet', 'for sure'])) {
      return _getVariedClip(clips['agreement']!, 'agreement');
    }
    
    // ü§î COMPLEX THINKING REQUIRED
    if (message.length > 100 || _containsAny(message, ['complex', 'difficult', 'think about', 'analyze', 'consider', 'strategy', 'plan', 'solution', 'algorithm', 'technical'])) {
      return _getVariedClip(clips['thinking']!, 'thinking');
    }
    
    // üîÑ FILLER TRANSITIONS (When user pauses or transitions)
    if (_containsAny(message, ['so', 'well', 'actually', 'basically', 'anyway', 'moving on', 'another thing'])) {
      return _getVariedClip(clips['filler_transitions']!, 'filler_transitions');
    }
    
    // üé≠ PLAYFUL CONTEXT (Detect humor, flirting, casual)
    if (_containsAny(message, ['funny', 'joke', 'haha', 'lol', 'cute', 'sweet', 'interesting choice']) && clips.containsKey('playful')) {
      return _getVariedClip(clips['playful']!, 'playful');
    }
    
    // üìà CONVERSATION FLOW ADAPTATION
    if (conversationTurn > 10) {
      // Later in conversation - more varied responses
      final categories = ['understanding', 'curiosity', 'agreement', 'thinking'];
      final randomCategory = categories[math.Random().nextInt(categories.length)];
      return _getVariedClip(clips[randomCategory]!, randomCategory);
    }
    
    // üéØ DEFAULT: Understanding with variety
    return _getVariedClip(clips['understanding']!, 'understanding');
  }

  // üîÑ VARIETY TRACKING - Prevents Repetition
  static String _getVariedClip(List<String> clips, String category) {
    // Filter out recently used clips
    final availableClips = clips.where((clip) => !_recentlyUsed.contains(clip)).toList();
    
    String selectedClip;
    if (availableClips.isNotEmpty) {
      selectedClip = availableClips[math.Random().nextInt(availableClips.length)];
    } else {
      // If all clips used recently, clear history and pick any
      _recentlyUsed.clear();
      selectedClip = clips[math.Random().nextInt(clips.length)];
    }
    
    // Track usage
    _recentlyUsed.add(selectedClip);
    if (_recentlyUsed.length > _maxHistorySize) {
      _recentlyUsed.removeAt(0);
    }
    
    print("üéµ Selected from $category: ${selectedClip.split('/').last}");
    return selectedClip;
  }

  // üéØ HELPER: Check if message contains any keywords
  static bool _containsAny(String message, List<String> keywords) {
    return keywords.any((keyword) => message.contains(keyword));
  }
}

// For non-blocking async calls
void unawaited(Future<void> future) {
  // Explicitly ignore the future
}

// üé≠ Voice states for UI
enum VoiceState {
  idle,
  listening,
  processing,
  speaking,
  backchanneling,
  error
}

class RealtimeVoiceChat extends StatefulWidget {
  final String personality;
  final String baseUrl;

  const RealtimeVoiceChat({
    Key? key,
    required this.personality,
    required this.baseUrl,
  }) : super(key: key);

  @override
  State<RealtimeVoiceChat> createState() => _RealtimeVoiceChatState();
}

class _RealtimeVoiceChatState extends State<RealtimeVoiceChat>
    with TickerProviderStateMixin {
  
  // üé§ Voice Recognition
  late stt.SpeechToText _speechToText;
  late AudioPlayer _audioPlayer;
  late AudioPlayer _backchannelPlayer; // Separate player for instant clips
  late FlutterTts _flutterTts;
  bool _speechEnabled = false;
  bool _isListening = false;
  String _wordsSpoken = "";
  double _confidenceLevel = 0;
  
  // üé≠ UI Animation Controllers
  late AnimationController _pulseController;
  late AnimationController _listeningController;
  late AnimationController _speakingController;
  late AnimationController _thinkingController;
  late AnimationController _backchannelController;
  
  late Animation<double> _pulseScale;
  late Animation<double> _listeningPulse;
  late Animation<double> _speakingBounce;
  late Animation<double> _thinkingRotation;
  late Animation<double> _backchannelPulse;
  
  // üß† PERSISTENT MEMORY & CONVERSATION STATE
  String _currentStatus = "Ready to chat!";
  String _lastAiResponse = "";
  List<Map<String, String>> _conversationHistory = [];
  VoiceState _currentState = VoiceState.idle;
  String? _persistentUserId;
  int _totalConversations = 0;
  bool _hasLoadedMemory = false;
  Timer? _speechProcessingTimer;
  String _lastProcessedText = "";
  bool _isCurrentlyProcessing = false;

  // üéµ BACKCHANNEL AUDIO SYSTEM
  List<String> _backchannelClips = [];
  List<String> _emotionClips = [];
  List<String> _greetingClips = [];
  bool _isBackchannelPlaying = false;
  String? _queuedRealResponse;
  Timer? _backchannelTimer;
  int _conversationTurn = 0;

  // üé≠ Personality Configurations
  Map<String, Map<String, dynamic>> get _personalityConfig => {
    'Lana Croft': {
      'voiceId': 'QXEkTn58Ik1IKjIMk8QA',
      'color': Colors.amber,
      'greeting': 'Ready for an adventure?'
    },
    'Baxter Jordan': {
      'voiceId': 'pNInz6obpgDQGcFmaJgB',
      'color': Colors.blue,
      'greeting': 'Let\'s analyze this situation...'
    },
  };

  // üéµ COMPREHENSIVE BACKCHANNEL AUDIO CLIPS CONFIGURATION
  Map<String, List<String>> get _audioClipsByType => {
    // ‚úÖ QUICK ACKNOWLEDGMENTS (Most Frequent)
    'acknowledgment': [
      'assets/audio/backchannel/stronger_Mmhmm_acknowledgement.mp3',
      'assets/audio/backchannel/happy_Mmhmm_acknowledgement.mp3',
      'assets/audio/backchannel/clearing_throat_choking_Mhmm.mp3',
      'assets/audio/backchannel/Got_It_Acknowledge.mp3',
      'assets/audio/backchannel/Lively_Right_Acknowledge.mp3',
      'assets/audio/backchannel/Average_I_Get_It.mp3',
      'assets/audio/backchannel/sarcastic_Mmhmm.mp3', // For variety!
    ],

    // üß† UNDERSTANDING & PROCESSING
    'understanding': [
      'assets/audio/backchannel/I_see_caring.mp3',
      'assets/audio/backchannel/Average_That_Makes_Sense.mp3',
      'assets/audio/backchannel/Average_Totally.mp3',
      'assets/audio/backchannel/Average_Of_Course.mp3',
      'assets/audio/backchannel/Average_For_Sure.mp3',
      'assets/audio/backchannel/Average_Absolutely_Version_2.mp3',
    ],

    // ü§î CURIOSITY & QUESTIONS
    'curiosity': [
      'assets/audio/backchannel/Curious_Really.mp3',
      'assets/audio/backchannel/Oh_Wow.mp3',
      'assets/audio/backchannel/Surprised_OOooh.mp3',
      'assets/audio/backchannel/Very_Intrigued_Thats_a_Good_Question.mp3',
      'assets/audio/backchannel/Seriously_Question.mp3',
      'assets/audio/backchannel/No_Way.mp3',
      'assets/audio/backchannel/Breathing_Whoa_No_Kidding.mp3',
      'assets/audio/backchannel/I_Had_No_Idea.mp3',
    ],

    // üéØ AGREEMENT & CONFIRMATION
    'agreement': [
      'assets/audio/backchannel/Agreement_Exactly.mp3',
      'assets/audio/backchannel/Totally_Agree.mp3',
      'assets/audio/backchannel/Youre_Right.mp3',
      'assets/audio/backchannel/100_Percent.mp3',
      'assets/audio/backchannel/Definitely.mp3',
      'assets/audio/backchannel/Upbeat_Absolutely.mp3',
    ],

    // ü§Ø THINKING & PROCESSING (Complex Topics)
    'thinking': [
      'assets/audio/backchannel/OH_Let_Me_Process_That.mp3',
      'assets/audio/backchannel/Laughing_Let_Me_Think_About_That.mp3',
      'assets/audio/backchannel/Breathing_Chuckle_Let_Me_Think_About_That.mp3',
      'assets/audio/backchannel/Genuine_Laughing_While_Saying_Let_Me_Think_About_That.mp3',
      'assets/audio/backchannel/Flirty_Laughing_Let_Me_Think_About_That_Thats_Good_Question.mp3',
      'assets/audio/backchannel/filler_quick_hmm.mp3',
    ],

    // üéâ EXCITEMENT & POSITIVE REACTIONS
    'excitement': [
      'assets/audio/backchannel/excited_YEAH.mp3',
      'assets/audio/backchannel/Thats_Amazing.mp3',
      'assets/audio/backchannel/Thats_Wild.mp3',
      'assets/audio/backchannel/Cool.mp3',
      'assets/audio/backchannel/small_chuckle_yeah.mp3',
    ],

    // üíô EMPATHY & CARING
    'empathy': [
      'assets/audio/backchannel/That_Sucks.mp3',
      'assets/audio/backchannel/Caring_Empathetic_Oh_Man.mp3',
      'assets/audio/backchannel/Caring_I_Feel_You.mp3',
      'assets/audio/backchannel/Caring_I_Understand.mp3',
      'assets/audio/backchannel/Caring_Thats_Tough.mp3',
    ],

    // üîÑ FILLER TRANSITIONS (Natural Flow)
    'filler_transitions': [
      'assets/audio/backchannel/Filler_Soo.mp3',
      'assets/audio/backchannel/Filler_The_Way_I_See_It.mp3',
      'assets/audio/backchannel/Filler_Wellll.mp3',
      'assets/audio/backchannel/Filler_Yeah_Well.mp3',
      'assets/audio/backchannel/Filler_Actually.mp3',
      'assets/audio/backchannel/Filler_I_Mean.mp3',
      'assets/audio/backchannel/Filer_Heres_The_Thing.mp3',
      'assets/audio/backchannel/Filler_Mmm_Okay.mp3',
      'assets/audio/backchannel/Filler_Huh_Lets_See.mp3',
      'assets/audio/backchannel/Filler_Slightly_Annoyed_Yea_Well.mp3',
    ],

    // üé≠ PLAYFUL & PERSONALITY
    'playful': [
      'assets/audio/backchannel/Filler_Playful_Mmmmm.mp3',
      'assets/audio/backchannel/Sensual_Moan_Explicit.mp3', // Interesting choice! üòè
    ],
  };

  @override
  void initState() {
    super.initState();
    _initializeVoiceChat();
    _setupAnimations();
    _loadPersistentMemory();
    _preloadAudioClips();
    
    // üöÄ Auto-start ChatGPT-style listening after initialization
    Timer(Duration(seconds: 3), () {
      if (mounted && _speechEnabled) {
        print("üé§ Auto-starting ChatGPT-style voice system...");
        setState(() {
          _currentStatus = "Ready to chat - just start speaking!";
        });
        _startListening();
      }
    });
  }

  // üéµ PRELOAD AUDIO CLIPS FOR INSTANT PLAYBACK
  Future<void> _preloadAudioClips() async {
    try {
      print("üéµ Preloading ALL backchannel audio clips...");
      
      int totalClips = 0;
      for (String category in _audioClipsByType.keys) {
        for (String clipPath in _audioClipsByType[category]!) {
          try {
            await _backchannelPlayer.setSource(AssetSource(clipPath.replaceFirst('assets/', '')));
            totalClips++;
            print("‚úÖ Preloaded: ${clipPath.split('/').last}");
          } catch (e) {
            print("‚ö†Ô∏è Failed to preload $clipPath: $e");
          }
        }
      }
      
      print("üéµ Successfully preloaded $totalClips backchannel clips!");
      
    } catch (e) {
      print("‚ùå Error preloading audio clips: $e");
    }
  }

  // üß† ENHANCED ML-BASED CLIP SELECTION
  String _selectBackchannelClip(String userMessage, int conversationTurn) {
    return BackchannelSelector.selectBackchannelClip(userMessage, conversationTurn, _audioClipsByType);
  }

  // üß† FALLBACK: SIMPLE ML-BASED CLIP SELECTION (If Enhanced Fails)
  String _selectBackchannelClipSimple(String userMessage, int conversationTurn) {
    final message = userMessage.toLowerCase();
    final clips = _audioClipsByType;
    
    print("üß† ML selecting clip for: '$userMessage' (turn $conversationTurn)");
    
    // üéØ CONTEXT-BASED SELECTION
    
    // First turn - more acknowledgment
    if (conversationTurn <= 2) {
      return _getRandomClip(clips['acknowledgment']!);
    }
    
    // Detect emotional context
    if (message.contains('problem') || message.contains('issue') || 
        message.contains('stuck') || message.contains('wrong')) {
      return _getRandomClip(clips['empathy']!);
    }
    
    // Detect excitement
    if (message.contains('awesome') || message.contains('amazing') || 
        message.contains('great') || message.contains('love')) {
      return _getRandomClip(clips['excitement']!);
    }
    
    // Detect questions or curiosity
    if (message.contains('?') || message.contains('what') || 
        message.contains('how') || message.contains('why')) {
      return _getRandomClip(clips['curiosity']!);
    }
    
    // Detect agreement/confirmation
    if (message.contains('exactly') || message.contains('yes') || 
        message.contains('right') || message.contains('agree')) {
      return _getRandomClip(clips['agreement']!);
    }
    
    // Detect thinking/complex topics
    if (message.length > 50 || message.contains('complex') || 
        message.contains('difficult') || message.contains('think')) {
      return _getRandomClip(clips['thinking']!);
    }
    
    // Default to understanding
    return _getRandomClip(clips['understanding']!);
  }

  String _getRandomClip(List<String> clips) {
    final random = math.Random();
    return clips[random.nextInt(clips.length)];
  }

  // üéµ INSTANT BACKCHANNEL RESPONSE (Non-blocking)
  Future<void> _playBackchannelClip(String userMessage) async {
    if (_isBackchannelPlaying) return;
    
    setState(() {
      if (!mounted) return;
      _currentState = VoiceState.backchanneling;
      _currentStatus = "Responding naturally...";
      _isBackchannelPlaying = true;
    });
    
    try {
      // Select appropriate clip using Enhanced ML
      final clipPath = _selectBackchannelClip(userMessage, _conversationTurn);
      print("üöÄ INSTANT: Playing backchannel clip: $clipPath");
      
      _backchannelController.repeat(reverse: true);
      
      // Play the instant response clip (non-blocking)
      final assetPath = clipPath.replaceFirst('assets/', '');
      unawaited(_backchannelPlayer.play(AssetSource(assetPath)));
      
      // Don't wait for completion - let it play while backend processes
      _backchannelPlayer.onPlayerComplete.first.then((_) {
        print("‚úÖ Backchannel clip completed in background");
        if (mounted) {
          setState(() {
            _isBackchannelPlaying = false;
          });
          _backchannelController.stop();
        }
      }).catchError((e) {
        print("‚ùå Backchannel completion error: $e");
        if (mounted) {
          setState(() {
            _isBackchannelPlaying = false;
          });
          _backchannelController.stop();
        }
      });
      
    } catch (e) {
      print("‚ùå Error playing backchannel clip: $e");
      if (mounted) {
        setState(() {
          _isBackchannelPlaying = false;
        });
        _backchannelController.stop();
      }
    }
  }

  // üó£Ô∏è Check for filler words
  bool _isJustFillerWords(String text) {
    final fillers = ['um', 'umm', 'uh', 'uhh', 'hmm', 'ah', 'er', 'like'];
    final words = text.toLowerCase().trim().split(' ');
    
    final meaningfulWords = words.where((word) => 
      word.length > 2 && !fillers.contains(word)
    ).toList();
    
    return meaningfulWords.isEmpty || text.trim().length < 5;
  }

  // üîÑ Auto-restart method with conversation tracking
  Future<void> _resetToIdleAndRestart() async {
    setState(() {
      _currentState = VoiceState.idle;
      _currentStatus = "Ready for next conversation...";
    });
    
    _thinkingController.stop();
    _speakingController.stop();
    _listeningController.stop();
    _backchannelController.stop();
    
    _isCurrentlyProcessing = false;
    _conversationTurn++; // Track conversation progress
    
    print("üîÑ Conversation turn: $_conversationTurn, restarting in 1s...");
    
    await Future.delayed(Duration(seconds: 1));
    
    if (mounted && _speechEnabled) {
      print("üé§ Auto-restarting ChatGPT-style listening...");
      _startListening();
    }
  }

  // üß† PERSISTENT MEMORY MANAGEMENT
  Future<void> _loadPersistentMemory() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      
      _persistentUserId = prefs.getString('persistent_user_id');
      if (_persistentUserId == null) {
        _persistentUserId = const Uuid().v4();
        await prefs.setString('persistent_user_id', _persistentUserId!);
        print("üÜî Created new persistent user ID: $_persistentUserId");
      } else {
        print("üÜî Loaded existing user ID: $_persistentUserId");
      }
      
      final historyJson = prefs.getString('conversation_history_${widget.personality}');
      if (historyJson != null) {
        final historyList = json.decode(historyJson) as List;
        _conversationHistory = historyList.map((item) => 
          Map<String, String>.from(item)).toList();
        
        if (_conversationHistory.length > 20) {
          _conversationHistory = _conversationHistory.sublist(_conversationHistory.length - 20);
          await _savePersistentMemory();
        }
        
        print("üìö Loaded ${_conversationHistory.length} previous conversations");
      }
      
      _totalConversations = prefs.getInt('total_conversations_${widget.personality}') ?? 0;
      await _loadBackendMemory();
      
      setState(() {
        _hasLoadedMemory = true;
        if (_conversationHistory.isNotEmpty) {
          _currentStatus = "${widget.personality} remembers your ${_conversationHistory.length} previous conversations!";
        } else {
          _currentStatus = "${widget.personality} is ready to start building memories with you!";
        }
      });
      
    } catch (e) {
      print("‚ùå Error loading persistent memory: $e");
      _persistentUserId = const Uuid().v4();
      setState(() {
        _hasLoadedMemory = true;
        _currentStatus = "Ready to chat!";
      });
    }
  }

  Future<void> _savePersistentMemory() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      
      await prefs.setString(
        'conversation_history_${widget.personality}',
        json.encode(_conversationHistory)
      );
      
      await prefs.setInt('total_conversations_${widget.personality}', _totalConversations);
      
      print("üíæ Saved conversation history: ${_conversationHistory.length} conversations");
      
    } catch (e) {
      print("‚ùå Error saving persistent memory: $e");
    }
  }

  Future<void> _loadBackendMemory() async {
    try {
      if (_persistentUserId == null) return;
      
      final response = await http.get(
        Uri.parse('${widget.baseUrl}/voice-conversation/memory/$_persistentUserId'),
      );
      
      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        if (data['success'] == true) {
          final memory = data['memory'];
          final stats = data['stats'];
          
          print("‚òÅÔ∏è Backend memory loaded:");
          print("   - Total conversations: ${memory['totalConversations']}");
          print("   - Recent patterns: ${memory['recentPatterns']}");
          
          _totalConversations = memory['totalConversations'] ?? 0;
        }
      }
    } catch (e) {
      print("‚ùå Error loading backend memory: $e");
    }
  }

  void _addToConversationHistory(String userMessage, String aiResponse) {
    final conversationEntry = {
      'user': userMessage,
      'assistant': aiResponse,
      'timestamp': DateTime.now().toIso8601String(),
      'personality': widget.personality,
    };
    
    setState(() {
      _conversationHistory.add(conversationEntry);
      _totalConversations++;
      
      if (_conversationHistory.length > 20) {
        _conversationHistory = _conversationHistory.sublist(_conversationHistory.length - 20);
      }
    });
    
    _savePersistentMemory();
  }

  void _setupAnimations() {
    _pulseController = AnimationController(
      duration: Duration(milliseconds: 2000),
      vsync: this,
    );
    _pulseScale = Tween<double>(begin: 1.0, end: 1.1).animate(
      CurvedAnimation(parent: _pulseController, curve: Curves.easeInOut),
    );
    
    _listeningController = AnimationController(
      duration: Duration(milliseconds: 800),
      vsync: this,
    );
    _listeningPulse = Tween<double>(begin: 1.0, end: 1.3).animate(
      CurvedAnimation(parent: _listeningController, curve: Curves.easeInOut),
    );
    
    _speakingController = AnimationController(
      duration: Duration(milliseconds: 400),
      vsync: this,
    );
    _speakingBounce = Tween<double>(begin: 1.0, end: 1.2).animate(
      CurvedAnimation(parent: _speakingController, curve: Curves.elasticOut),
    );
    
    _thinkingController = AnimationController(
      duration: Duration(milliseconds: 1500),
      vsync: this,
    );
    _thinkingRotation = Tween<double>(begin: 0.0, end: 1.0).animate(
      CurvedAnimation(parent: _thinkingController, curve: Curves.linear),
    );

    // üéµ NEW: Backchannel animation
    _backchannelController = AnimationController(
      duration: Duration(milliseconds: 600),
      vsync: this,
    );
    _backchannelPulse = Tween<double>(begin: 1.0, end: 1.15).animate(
      CurvedAnimation(parent: _backchannelController, curve: Curves.easeInOut),
    );
  }

  Future<void> _initializeVoiceChat() async {
    _speechToText = stt.SpeechToText();
    _audioPlayer = AudioPlayer();
    _backchannelPlayer = AudioPlayer(); // Separate player for instant clips
    _flutterTts = FlutterTts();
    
    await _flutterTts.setLanguage("en-US");
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setVolume(0.8);
    await _flutterTts.setPitch(1.0);
    
    _flutterTts.setCompletionHandler(() {
      print("üéµ TTS completed");
      if (mounted) {
        _resetToIdleAndRestart();
      }
    });
    
    try {
      _speechEnabled = await _speechToText.initialize(
        onStatus: _onSpeechStatus,
        onError: _onSpeechError,
      );
      
      if (_speechEnabled) {
        print("üé§ Speech recognition initialized successfully");
      }
      
    } catch (e) {
      print("‚ùå Failed to initialize speech recognition: $e");
      setState(() {
        _currentStatus = "Voice recognition not available. Using text mode.";
      });
    }
  }

  void _onSpeechStatus(String status) {
    print("üé§ Speech status: $status");
    
    if (status == "listening") {
      setState(() {
        _currentState = VoiceState.listening;
        _currentStatus = "Listening... speak naturally!";
      });
      _listeningController.repeat(reverse: true);
    }
  }

  void _onSpeechError(dynamic error) {
    print("‚ùå Speech error: $error");
    setState(() {
      _currentState = VoiceState.error;
      _currentStatus = "Voice error - will retry automatically!";
    });
    
    Timer(Duration(seconds: 3), () {
      _resetToIdleAndRestart();
    });
  }

  // üé§ CHATGPT-STYLE: Start Listening with Backchannel Support
  Future<void> _startListening() async {
    if (!_speechEnabled || _currentState != VoiceState.idle) return;

    try {
      setState(() {
        _currentState = VoiceState.listening;
        _currentStatus = "Listening... start speaking anytime!";
        _wordsSpoken = "";
      });

      HapticFeedback.lightImpact();
      _pulseController.stop();
      _listeningController.repeat(reverse: true);

      print("üé§ Starting ChatGPT-style auto-listening...");

      await _speechToText.listen(
        onResult: (result) {
          setState(() {
            _wordsSpoken = result.recognizedWords;
            _confidenceLevel = result.confidence;
          });
          
          print("üó£Ô∏è Speech result: '${result.recognizedWords}' (final: ${result.finalResult})");
          
          // üéØ SMART PROCESSING: Only process after real content + silence
          if (result.finalResult && 
              !_isCurrentlyProcessing && 
              _wordsSpoken.trim().length > 5 && 
              !_isJustFillerWords(_wordsSpoken)) {
            
            print("ü§î Potential complete thought detected, waiting 2s to confirm...");
            
            Timer(Duration(seconds: 2), () {
              if (_wordsSpoken.trim() == result.recognizedWords.trim() && 
                  !_isCurrentlyProcessing) {
                
                print("‚úÖ User finished speaking, processing: '$_wordsSpoken'");

                _isCurrentlyProcessing = true;
                _lastProcessedText = _wordsSpoken;
                _processUserInputWithBackchannel(_wordsSpoken);
              } else {
                print("üîÑ User continued speaking, waiting longer...");
              }
            });
          }
        },
        listenFor: Duration(minutes: 10),
        pauseFor: Duration(seconds: 20),
        partialResults: true,
        localeId: "en_US",
        cancelOnError: true,
      );

    } catch (e) {
      print("‚ùå Error starting listening: $e");
      setState(() {
        _currentState = VoiceState.error;
        _currentStatus = "Voice error - will retry automatically!";
      });
      
      Timer(Duration(seconds: 3), () {
        _resetToIdleAndRestart();
      });
    }
  }

  // üéµ NEW: Instant backchannel with parallel processing  
  Future<void> _processUserInputWithBackchannel(String userText) async {
    if (userText.trim().isEmpty) {
      _resetToIdleAndRestart();
      return;
    }

    // üöÄ INSTANT: Start backchannel and backend call simultaneously
    if (userText.length > 10 && !_isJustFillerWords(userText)) {
      try {
        print("üöÄ Starting INSTANT backchannel + backend call in parallel");
        
        // Start both immediately - no waiting!
        final backchannelFuture = _playBackchannelClip(userText);
        final backendFuture = _processUserInput(userText);
        
        // Let them run in parallel - don't wait for backchannel to finish
        unawaited(backchannelFuture); // Fire and forget
        await backendFuture; // Wait for the real processing
        
      } catch (e) {
        print("‚ö†Ô∏è Parallel processing error: $e");
        // Fallback to normal processing
        await _processUserInput(userText);
      }
    } else {
      // Short messages skip backchannel
      await _processUserInput(userText);
    }
  }

  // üß† Process User Input with Backchannel Integration
  Future<void> _processUserInput(String userText) async {
    if (userText.trim().isEmpty) {
      _resetToIdleAndRestart();
      return;
    }

    setState(() {
      _currentState = VoiceState.processing;
      _currentStatus = "${widget.personality} is thinking...";
    });

    _listeningController.stop();
    _thinkingController.repeat();
    HapticFeedback.mediumImpact();

    try {
      print("üß† Processing: '$userText' with ${widget.personality}");
      
      final backendResponse = await _callBackendAPIWithMemory(userText);
      
      if (backendResponse != null && backendResponse['success'] == true) {
        final aiResponse = backendResponse['aiResponse'];
        final audioUrl = backendResponse['audioUrl'];
        final memoryStats = backendResponse['memoryStats'];
        
        setState(() {
          _lastAiResponse = aiResponse;
        });
        
        _addToConversationHistory(userText, aiResponse);
        
        print("üéØ AI Response: '$aiResponse'");
        print("üß† Memory Stats: $memoryStats");
        print("üîä Audio URL received: ${audioUrl != null ? 'Yes' : 'No'}");

        // üéµ SMART WAIT: Only wait if backchannel is still playing after backend is ready
        if (_isBackchannelPlaying) {
          print("üéµ Backend ready, waiting for backchannel to finish naturally...");
          
          // Wait max 3 seconds for backchannel to finish
          int waitCount = 0;
          while (_isBackchannelPlaying && mounted && waitCount < 30) {
            await Future.delayed(Duration(milliseconds: 100));
            waitCount++;
          }
          
          print("üîç DEBUG: Backchannel wait completed. Still playing: $_isBackchannelPlaying");
        }

        // Play real response - ENSURE THIS ALWAYS HAPPENS
        if (audioUrl != null && mounted) {
          print("üéµ Starting ElevenLabs audio playback...");
          try {
            await _playElevenLabsAudio(audioUrl);
            print("‚úÖ ElevenLabs audio completed successfully");
          } catch (e) {
            print("‚ùå ElevenLabs audio failed: $e");
            print("üéµ Falling back to TTS");
            await _simulateVoice(aiResponse);
          }
        } else {
          print("üéµ No audio URL or not mounted, using fallback TTS");
          await _simulateVoice(aiResponse);
        }

      } else {
        print("üéØ Backend failed, using smart mock response");
        final mockResponse = _getSmartMockResponse(userText);
        
        setState(() {
          _lastAiResponse = mockResponse;
        });
        
        await _simulateVoice(mockResponse);
        _resetToIdleAndRestart();
      }
      
    } catch (e) {
      print("‚ùå Error processing input: $e");
      setState(() {
        _currentState = VoiceState.error;
        _currentStatus = "Oops! Something went wrong. Restarting...";
      });
      
      Timer(Duration(seconds: 2), () {
        _resetToIdleAndRestart();
      });
    }
  }

  // üåê Backend API Call WITH MEMORY SUPPORT
  Future<Map<String, dynamic>?> _callBackendAPIWithMemory(String userText) async {
    try {
      if (_persistentUserId == null) {
        print("‚ùå No persistent user ID available");
        return null;
      }

      final flatHistory = <Map<String, String>>[];
      for (final entry in (_conversationHistory.length > 5 
          ? _conversationHistory.sublist(_conversationHistory.length - 5)
          : _conversationHistory)) {
        if (entry['user'] != null) {
          flatHistory.add({'role': 'user', 'content': entry['user']!});
        }
        if (entry['assistant'] != null) {
          flatHistory.add({'role': 'assistant', 'content': entry['assistant']!});
        }
      }

      final requestBody = {
        'userId': _persistentUserId,
        'personality': widget.personality,
        'userMessage': userText,
        'conversationHistory': flatHistory,
        'hasMemory': _conversationHistory.isNotEmpty,
        'totalConversations': _totalConversations,
      };

      print("üåê Sending request with memory:");
      print("   - User ID: $_persistentUserId");
      print("   - Conversation history: ${flatHistory.length} messages");
      print("   - Total conversations: $_totalConversations");

      final response = await http.post(
        Uri.parse('${widget.baseUrl}/voice-conversation/text-only'),
        headers: {'Content-Type': 'application/json'},
        body: json.encode(requestBody),
      ).timeout(Duration(seconds: 30));

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        print("‚úÖ Backend response received with memory support");
        return data;
      } else {
        print("‚ùå Backend error: ${response.statusCode}");
        print("‚ùå Response: ${response.body}");
        return null;
      }

    } catch (e) {
      print("‚ùå Network error: $e");
      return null;
    }
  }

  // üéµ Play ElevenLabs Audio (UPDATED for auto-restart)
  Future<void> _playElevenLabsAudio(String audioUrl) async {
    try {
      setState(() {
        _currentState = VoiceState.speaking;
        _currentStatus = "${widget.personality} is speaking...";
      });
      
      _thinkingController.stop();
      _speakingController.repeat(reverse: true);
      
      final base64Audio = audioUrl.split(',')[1];
      final audioBytes = base64Decode(base64Audio);
      
      print("üéµ ElevenLabs audio starting playback...");
      
      await _audioPlayer.play(BytesSource(audioBytes));
      await _audioPlayer.onPlayerComplete.first;
      
      print("‚úÖ ElevenLabs audio playback completed");
      
      setState(() {
        _currentStatus = "Memory updated! Ready for next conversation...";
      });
      
      _resetToIdleAndRestart();
      
    } catch (e) {
      print("‚ùå Error playing ElevenLabs audio: $e");
      await _simulateVoice(_lastAiResponse);
    }
  }

  // üéµ Fallback TTS (UPDATED for auto-restart)
  Future<void> _simulateVoice(String text) async {
    setState(() {
      _currentState = VoiceState.speaking;
      _currentStatus = "${widget.personality} is speaking...";
    });
    
    _thinkingController.stop();
    _speakingController.repeat(reverse: true);
    
    try {
      print("üéµ TTS speaking: '$text'");
      await _flutterTts.speak(text);
    } catch (e) {
      print("‚ùå TTS error: $e");
      _resetToIdleAndRestart();
    }
  }

  // ü§ñ Smart Mock Response
  String _getSmartMockResponse(String userInput) {
    final input = userInput.toLowerCase();
    
    if (_conversationHistory.isNotEmpty) {
      final lastConversation = _conversationHistory.last;
      if (lastConversation['user']?.toLowerCase().contains('hello') == true ||
          lastConversation['user']?.toLowerCase().contains('hi') == true) {
        return "Good to see you again! What's on your mind today?";
      }
    }
    
    if (input.contains('hello') || input.contains('hi')) {
      return _conversationHistory.isEmpty 
        ? "Hello! I'm ${widget.personality}. Great to meet you!"
        : "Welcome back! I remember our previous conversations.";
    }
    
    if (input.contains('how are you')) {
      return _conversationHistory.isEmpty
        ? "I'm doing well and excited to get to know you!"
        : "I'm great! I've been thinking about our last conversation.";
    }
    
    return _conversationHistory.isEmpty
      ? "That's interesting! Tell me more."
      : "Based on what we've discussed before, that's a fascinating point.";
  }

  @override
  Widget build(BuildContext context) {
    final config = _personalityConfig[widget.personality]!;
    final color = config['color'] as Color;
    
    return Container(
      padding: EdgeInsets.all(24),
      child: Column(
        children: [
          // üß† Memory Status Display
          if (_hasLoadedMemory && _conversationHistory.isNotEmpty)
            Container(
              margin: EdgeInsets.only(bottom: 16),
              padding: EdgeInsets.all(12),
              decoration: BoxDecoration(
                color: color.withOpacity(0.1),
                borderRadius: BorderRadius.circular(12),
                border: Border.all(color: color.withOpacity(0.3)),
              ),
              child: Row(
                children: [
                  Icon(Icons.memory, color: color, size: 20),
                  SizedBox(width: 8),
                  Expanded(
                    child: Text(
                      "üí≠ ${_conversationHistory.length} conversations remembered",
                      style: TextStyle(
                        color: color,
                        fontWeight: FontWeight.w600,
                        fontSize: 14,
                      ),
                    ),
                  ),
                ],
              ),
            ),
          
          // üé§ Voice Interface with Backchannel Indicator
          Expanded(
            child: Column(
              mainAxisAlignment: MainAxisAlignment.center,
              children: [
                // Animated Voice Indicator
                AnimatedBuilder(
                  animation: Listenable.merge([
                    _pulseScale,
                    _listeningPulse,
                    _speakingBounce,
                    _thinkingRotation,
                    _backchannelPulse,
                  ]),
                  builder: (context, child) {
                    double scale = 1.0;
                    Widget icon = Icon(Icons.mic, size: 48, color: Colors.white);
                    Color circleColor = color;
                    
                    switch (_currentState) {
                      case VoiceState.idle:
                        scale = _pulseScale.value;
                        icon = Icon(Icons.mic, size: 48, color: Colors.white);
                        break;
                      case VoiceState.listening:
                        scale = _listeningPulse.value;
                        icon = Icon(Icons.mic, size: 48, color: Colors.white);
                        break;
                      case VoiceState.processing:
                        scale = 1.0;
                        icon = Transform.rotate(
                          angle: _thinkingRotation.value * 2 * 3.14159,
                          child: Icon(Icons.psychology, size: 48, color: Colors.white),
                        );
                        break;
                      case VoiceState.speaking:
                        scale = _speakingBounce.value;
                        icon = Icon(Icons.volume_up, size: 48, color: Colors.white);
                        break;
                      case VoiceState.backchanneling:
                        scale = _backchannelPulse.value;
                        icon = Icon(Icons.hearing, size: 48, color: Colors.white);
                        circleColor = Colors.green; // Different color for backchannel
                        break;
                      case VoiceState.error:
                        scale = 1.0;
                        icon = Icon(Icons.error_outline, size: 48, color: Colors.white);
                        break;
                    }
                    
                    return Transform.scale(
                      scale: scale,
                      child: Container(
                        width: 120,
                        height: 120,
                        decoration: BoxDecoration(
                          color: circleColor,
                          shape: BoxShape.circle,
                          boxShadow: [
                            BoxShadow(
                              color: circleColor.withOpacity(0.3),
                              blurRadius: 20,
                              spreadRadius: 5,
                            ),
                          ],
                        ),
                        child: icon,
                      ),
                    );
                  },
                ),
                
                SizedBox(height: 32),
                
                // Status Text
                Text(
                  _currentStatus,
                  textAlign: TextAlign.center,
                  style: TextStyle(
                    fontSize: 18,
                    fontWeight: FontWeight.w600,
                    color: Colors.grey[800],
                  ),
                ),
                
                SizedBox(height: 16),
                
                // üéµ Backchannel Status Indicator
                if (_isBackchannelPlaying)
                  Container(
                    padding: EdgeInsets.symmetric(horizontal: 16, vertical: 8),
                    decoration: BoxDecoration(
                      color: Colors.green.withOpacity(0.1),
                      borderRadius: BorderRadius.circular(20),
                      border: Border.all(color: Colors.green.withOpacity(0.3)),
                    ),
                    child: Row(
                      mainAxisSize: MainAxisSize.min,
                      children: [
                        Icon(Icons.hearing, color: Colors.green, size: 16),
                        SizedBox(width: 8),
                        Text(
                          "Responding naturally...",
                          style: TextStyle(
                            color: Colors.green,
                            fontWeight: FontWeight.w500,
                            fontSize: 12,
                          ),
                        ),
                      ],
                    ),
                  ),
                
                // Conversation Flow Indicator
                if (_currentState == VoiceState.listening)
                  Container(
                    margin: EdgeInsets.only(top: 16),
                    padding: EdgeInsets.symmetric(horizontal: 16, vertical: 8),
                    decoration: BoxDecoration(
                      color: color.withOpacity(0.1),
                      borderRadius: BorderRadius.circular(20),
                      border: Border.all(color: color.withOpacity(0.3)),
                    ),
                    child: Row(
                      mainAxisSize: MainAxisSize.min,
                      children: [
                        Icon(Icons.hearing, color: color, size: 16),
                        SizedBox(width: 8),
                        Text(
                          "Always listening - speak naturally",
                          style: TextStyle(
                            color: color,
                            fontWeight: FontWeight.w500,
                            fontSize: 12,
                          ),
                        ),
                      ],
                    ),
                  ),
                
                // Last Response
                if (_lastAiResponse.isNotEmpty)
                  Container(
                    margin: EdgeInsets.only(top: 16),
                    padding: EdgeInsets.all(16),
                    decoration: BoxDecoration(
                      color: Colors.grey[100],
                      borderRadius: BorderRadius.circular(12),
                    ),
                    child: Text(
                      _lastAiResponse,
                      style: TextStyle(
                        fontSize: 16,
                        color: Colors.grey[700],
                        fontStyle: FontStyle.italic,
                      ),
                    ),
                  ),
              ],
            ),
          ),
        ],
      ),
    );
  }

  @override
  void dispose() {
    _speechProcessingTimer?.cancel();
    _backchannelTimer?.cancel();
    _pulseController.dispose();
    _listeningController.dispose();
    _speakingController.dispose();
    _thinkingController.dispose();
    _backchannelController.dispose();
    _audioPlayer.dispose();
    _backchannelPlayer.dispose();
    super.dispose();
  }
}